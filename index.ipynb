{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant modules\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import imblearn\n",
    "import sklearn\n",
    "import os\n",
    "import io\n",
    "import pygraphviz\n",
    "import pydotplus\n",
    "import imageio\n",
    "import itertools\n",
    "#import xgboost as xgb\n",
    "\n",
    "from scipy import misc\n",
    "from scipy import stats\n",
    "from IPython.display import Image\n",
    "from sklearn import tree  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.set_printoptions(precision=3)\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset loading\n",
    "#FullDataframe = pd.read_csv(\"D:/DataSets/CIC-IDS-2017/MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\") \n",
    "\n",
    "\"\"\"\n",
    "from glob import glob\n",
    "dfs = []\n",
    "for file in sorted(glob('\"D:/DataSets/CIC-IDS-2017/MachineLearningCVE/*.csv')):\n",
    "    print(file)\n",
    "    dfs.append(pd.read_csv(file))\n",
    "FullDataframe = pd.concat(dfs)\n",
    "\"\"\"\n",
    "\n",
    "df6=pd.read_csv(\"C:/Users/QuatroPC/Desktop/Projeto4/DataSets/Canada 2017/MachineLearningCSV/MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\")\n",
    "#df7=pd.read_csv(\"C:/Users/QuatroPC/Desktop/Projeto4/DataSets/Canada 2017/MachineLearningCSV/MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv\")\n",
    "#df8=pd.read_csv(\"C:/Users/QuatroPC/Desktop/Projeto4/DataSets/Canada 2017/MachineLearningCSV/MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv\")\n",
    "\n",
    "FullDataframe = pd.concat([df6])\n",
    "print(\"Original version has {} rows & {} columns\".format(FullDataframe.shape[0],FullDataframe.shape[1]))\n",
    "\n",
    "FullDataframe = FullDataframe.drop_duplicates()\n",
    "print(\"No-duplicates version has {} rows & {} columns\".format(FullDataframe.shape[0],FullDataframe.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FullDataframe.groupby('Label').first()\n",
    "FullDataframe[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FullDataframe.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FullDataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FullDataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FullDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(FullDataframe, test_size = 0.20, random_state=10)\n",
    "\n",
    "train[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train[' Label']\n",
    "train_x = train.drop([' Label'], axis=1)\n",
    "#train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x2 = train_x\n",
    "train_x = train_x.values.astype(np.long)\n",
    "np.nan_to_num(train_x)\n",
    "\n",
    "#train_x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and Random Forest model and most important features\n",
    "DTC_Classifier = DecisionTreeClassifier()\n",
    "DTC_Classifier.fit(train_x, train_y);\n",
    "\n",
    "score = np.round(DTC_Classifier.feature_importances_,3)\n",
    "importances = pd.DataFrame({'feature':train_x2.columns,'importance':score})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "# plot importances\n",
    "plt.rcParams['figure.figsize'] = (11, 4)\n",
    "importances.plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the RFE model and select 15 attributes\n",
    "KN_Classifier_RFE = DecisionTreeClassifier()\n",
    "train_test = train\n",
    "\n",
    "rfe = RFE(KN_Classifier_RFE, n_features_to_select=15)\n",
    "rfe = rfe.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the selection of the attributes\n",
    "feature_map = [(i, v) for i, v in itertools.zip_longest(rfe.get_support(), train_x2.columns)]\n",
    "selected_features = [v for i, v in feature_map if i==True]\n",
    "\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train KNeighborsClassifier Model\n",
    "KNN_Classifier = KNeighborsClassifier(n_jobs=-1)\n",
    "KNN_Classifier.fit(train_x, train_y); \n",
    "\n",
    "# Train LogisticRegression Model\n",
    "LGR_Classifier = LogisticRegression(n_jobs=-1, random_state=42)\n",
    "LGR_Classifier.fit(train_x, train_y);\n",
    "\n",
    "# Train Gaussian Naive Baye Model\n",
    "BNB_Classifier = BernoulliNB()\n",
    "BNB_Classifier.fit(train_x, train_y)\n",
    "            \n",
    "# Train Decision Tree Model\n",
    "DTC_Classifier = tree.DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "DTC_Classifier.fit(train_x, train_y)\n",
    "\n",
    "# Already trained Random Forest Model -> RFC_Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "models = []\n",
    "models.append(('Naive_Baye', BNB_Classifier))\n",
    "models.append(('Decision_Tree', DTC_Classifier))\n",
    "models.append(('KNeighbors', KNN_Classifier))\n",
    "models.append(('Logistic_Regression', LGR_Classifier))\n",
    "\n",
    "for i, v in models:\n",
    "    scores = cross_val_score(v, train_x, train_y, cv=100)\n",
    "    accuracy = metrics.accuracy_score(train_y, v.predict(train_x))\n",
    "    confusion_matrix = metrics.confusion_matrix(train_y, v.predict(train_x))\n",
    "    classification = metrics.classification_report(train_y, v.predict(train_x))\n",
    "    print()\n",
    "    print('============================== {} Model Evaluation =============================='.format(i))\n",
    "    print()\n",
    "    print (\"Cross Validation Mean Score:\" \"\\n\", scores.mean())\n",
    "    print()\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification report:\" \"\\n\", classification) \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test[' Label']\n",
    "test_x = test.drop([' Label'], axis=1)\n",
    "test_y\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_x.values.astype(np.long)\n",
    "np.nan_to_num(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in models:\n",
    "    accuracy = metrics.accuracy_score(test_y, v.predict(test_x))\n",
    "    confusion_matrix = metrics.confusion_matrix(test_y, v.predict(test_x))\n",
    "    classification = metrics.classification_report(test_y, v.predict(test_x))\n",
    "    print()\n",
    "    print('============================== {} Model Test Results =============================='.format(i))\n",
    "    print()\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification report:\" \"\\n\", classification) \n",
    "    print()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_knn = KNN_Classifier.predict(test_x)\n",
    "pred_NB = BNB_Classifier.predict(test_x)\n",
    "pred_log = LGR_Classifier.predict(test_x)\n",
    "pred_dt = DTC_Classifier.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for i, v in models:\n",
    "        print(i)\n",
    "        filename = 'model_'+i+'.sav'\n",
    "        pickle.dump(v, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
